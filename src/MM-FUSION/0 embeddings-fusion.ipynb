{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **A Novel Approach for Three-Way Classification of Lumbar Spine Degeneration Using Pseudo-Modality Learning to Handle Missing MRI Data**"]},{"cell_type":"markdown","metadata":{},"source":["## Libs"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:05:45.741424Z","iopub.status.busy":"2024-10-07T16:05:45.740795Z","iopub.status.idle":"2024-10-07T16:05:45.746602Z","shell.execute_reply":"2024-10-07T16:05:45.745506Z","shell.execute_reply.started":"2024-10-07T16:05:45.741383Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import random\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{},"source":["## Loading MedicalNet50 Embeddings"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:02:57.017298Z","iopub.status.busy":"2024-10-07T16:02:57.016871Z","iopub.status.idle":"2024-10-07T16:02:58.838664Z","shell.execute_reply":"2024-10-07T16:02:58.837890Z","shell.execute_reply.started":"2024-10-07T16:02:57.017265Z"},"trusted":true},"outputs":[],"source":["csv1 = pd.read_csv('/kaggle/input/medicalnet-attention-layers-for-rsna/AT2_attention_embeddings_hist.csv')\n","csv2 = pd.read_csv('/kaggle/input/medicalnet-attention-layers-for-rsna/ST1_attention_embeddings_hist.csv')\n","csv3 = pd.read_csv('/kaggle/input/medicalnet-attention-layers-for-rsna/ST2_attention_embeddings_hist.csv')\n","\n","merged_data = pd.concat([csv1, csv2, csv3], ignore_index=True)\n","\n","unique_study_ids = merged_data['study_id'].unique()\n","train_ids, test_ids = train_test_split(unique_study_ids, test_size=0.2, random_state=42)\n","\n","train_data = merged_data[merged_data['study_id'].isin(train_ids)]\n","test_data = merged_data[merged_data['study_id'].isin(test_ids)]\n","\n","def simulate_missing_modalities(data, missing_rate=0.5):\n","    grouped = data.groupby('study_id')\n","    simulated_data = []\n","    \n","    for study_id, group in grouped:\n","        num_embeddings = len(group)\n","        num_to_keep = max(1, int(num_embeddings * (1 - missing_rate)))  \n","        keep_indices = random.sample(range(num_embeddings), num_to_keep)\n","        for idx in keep_indices:\n","            simulated_data.append(group.iloc[idx])\n","    \n","    return pd.DataFrame(simulated_data)\n","\n","simulated_test_data = simulate_missing_modalities(test_data, missing_rate=0.5)"]},{"cell_type":"markdown","metadata":{},"source":["## Defining Architecture"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:02:58.840131Z","iopub.status.busy":"2024-10-07T16:02:58.839807Z","iopub.status.idle":"2024-10-07T16:02:58.855183Z","shell.execute_reply":"2024-10-07T16:02:58.854221Z","shell.execute_reply.started":"2024-10-07T16:02:58.840099Z"},"trusted":true},"outputs":[],"source":["class DenoisingAutoencoder(nn.Module):\n","    def __init__(self, input_dim=512, hidden_dim=256, output_dim=512):\n","        super(DenoisingAutoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, hidden_dim)\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, output_dim),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded\n","    \n","class VAE(nn.Module):\n","    def __init__(self, input_dim=512, latent_dim=128):\n","        super(VAE, self).__init__()\n","        \n","        self.fc1 = nn.Linear(input_dim, 256)\n","        self.fc21 = nn.Linear(256, latent_dim)\n","        self.fc22 = nn.Linear(256, latent_dim)\n","        \n","        self.fc3 = nn.Linear(latent_dim, 256)\n","        self.fc4 = nn.Linear(256, input_dim)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","    \n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","    \n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.tanh(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","def vae_loss_function(reconstructed_x, x, mu, logvar):\n","    recon_loss = F.mse_loss(reconstructed_x, x, reduction='sum')\n","    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    \n","    return recon_loss + kl_loss\n","\n","class AttentionFusion(nn.Module):\n","    def __init__(self, embedding_dim=512):\n","        super(AttentionFusion, self).__init__()\n","        self.attention_weights = nn.Parameter(torch.ones(1, embedding_dim), requires_grad=True)\n","\n","    def forward(self, embeddings):\n","        attention_scores = torch.matmul(embeddings, self.attention_weights.T)\n","        attention_weights = torch.softmax(attention_scores, dim=0)\n","\n","        fused_embedding = torch.sum(attention_weights * embeddings, dim=0)\n","        return fused_embedding"]},{"cell_type":"markdown","metadata":{},"source":["## Training Functions"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:06:16.422215Z","iopub.status.busy":"2024-10-07T16:06:16.421608Z","iopub.status.idle":"2024-10-07T16:06:16.445219Z","shell.execute_reply":"2024-10-07T16:06:16.444385Z","shell.execute_reply.started":"2024-10-07T16:06:16.422177Z"},"trusted":true},"outputs":[],"source":["def train_denoising_autoencoder(autoencoder, optimizer, train_data, num_epochs=50, noise_factor=0.2):\n","    autoencoder.train()\n","    grouped = train_data.groupby('study_id')\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    autoencoder.to(device)\n","\n","    mse_loss_fn = nn.MSELoss()\n","\n","    for epoch in tqdm(range(num_epochs)):\n","        total_loss = 0\n","        for study_id, group in (grouped):\n","\n","            embeddings = []\n","            for _, row in group.iterrows():\n","                embedding = row[0:512].to_numpy(dtype=float)  \n","                embeddings.append(embedding)\n","\n","            embeddings = np.array(embeddings)  \n","\n","            num_embeddings = embeddings.shape[0]\n","\n","            if num_embeddings > 1:\n","                input_embeddings = embeddings[0]\n","                noisy_embeddings = input_embeddings + noise_factor * np.random.randn(*input_embeddings.shape)  # Add noise\n","                noisy_embeddings = np.clip(noisy_embeddings, 0., 1.)\n","                \n","                input_embeddings = torch.tensor(input_embeddings, dtype=torch.float32).to(device)\n","                noisy_embeddings = torch.tensor(noisy_embeddings, dtype=torch.float32).to(device)\n","\n","                reconstructed_embeddings = autoencoder(noisy_embeddings)\n","\n","                loss = mse_loss_fn(reconstructed_embeddings, input_embeddings)\n","                total_loss += loss.item()\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","    print(f'Total Loss: {total_loss/len(grouped)}')\n","        \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def train_vae(vae, optimizer, train_data, num_epochs=50):\n","    vae.train()\n","    grouped = train_data.groupby('study_id')\n","    \n","    for epoch in tqdm(range(num_epochs)):\n","        total_loss = 0\n","        for study_id, group in (grouped):\n","\n","            embeddings = []\n","            for _, row in group.iterrows():\n","                embedding = row[0:512].to_numpy(dtype=float)  \n","                embeddings.append(embedding)\n","\n","            embeddings = np.array(embeddings)\n","\n","            if len(embeddings) > 1:\n","                input_embedding = embeddings[0]\n","                noisy_embedding = input_embedding + 0.3 * np.random.randn(*input_embedding.shape)  # Add noise\n","\n","                input_embedding = torch.tensor(input_embedding, dtype=torch.float32).to(device)\n","                noisy_embedding = torch.tensor(noisy_embedding, dtype=torch.float32).to(device)\n","\n","                optimizer.zero_grad()\n","\n","                reconstructed_embedding, mu, logvar = vae(noisy_embedding)\n","\n","                loss = vae_loss_function(reconstructed_embedding, input_embedding, mu, logvar)\n","\n","                total_loss += loss.item()\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","    print(f'Total Loss: {total_loss/len(grouped)}')\n","\n","fusion_layer = AttentionFusion(embedding_dim=512).to(device)\n","\n","def train_with_attention_fusion(vae, optimizer, train_data, num_epochs=50):\n","    vae.train()\n","    fusion_layer.train()\n","    grouped = train_data.groupby('study_id')\n","    \n","    for epoch in tqdm(range(num_epochs)):\n","        total_loss = 0\n","        for study_id, group in (grouped):\n","            embeddings = []\n","            for _, row in group.iterrows():\n","                embedding = row[0:512].to_numpy(dtype=float)  \n","                embeddings.append(embedding)\n","\n","            embeddings = np.array(embeddings)\n","\n","            if len(embeddings) > 1:\n","                embeddings_tensor = torch.tensor(embeddings, dtype=torch.float32).to(device)\n","                \n","                fused_embedding = fusion_layer(embeddings_tensor)\n","\n","                noisy_embedding = fused_embedding + 0.3 * torch.randn(*fused_embedding.shape).to(device)\n","\n","                optimizer.zero_grad()\n","                reconstructed_embedding, mu, logvar = vae(noisy_embedding)\n","\n","                loss = vae_loss_function(reconstructed_embedding, fused_embedding, mu, logvar)\n","\n","                total_loss += loss.item()\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","    print(f'Total Loss: {total_loss/len(grouped)}')"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:06:21.965153Z","iopub.status.busy":"2024-10-07T16:06:21.964392Z","iopub.status.idle":"2024-10-07T16:10:30.200682Z","shell.execute_reply":"2024-10-07T16:10:30.199819Z","shell.execute_reply.started":"2024-10-07T16:06:21.965110Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [01:10<00:00,  3.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Total Loss: 52.91559053136459\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [01:28<00:00,  4.44s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Total Loss: 27095.971876089767\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [01:29<00:00,  4.46s/it]"]},{"name":"stdout","output_type":"stream","text":["Total Loss: 13440.086152139622\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["autoencoder = DenoisingAutoencoder(input_dim=512, hidden_dim=256, output_dim=512)\n","optimizer = optim.Adam(autoencoder.parameters(), lr=0.0001)\n","\n","train_denoising_autoencoder(autoencoder, optimizer, train_data, num_epochs=20)\n","\n","vae = VAE(input_dim=512, latent_dim=256).to(device)\n","optimizer = optim.Adam(vae.parameters(), lr=0.001)\n","\n","train_vae(vae, optimizer, train_data, num_epochs=20)\n","\n","attention_fusion = VAE(input_dim=512, latent_dim=128).to(device)\n","optimizer = optim.Adam(vae.parameters(), lr=0.001)\n","\n","train_with_attention_fusion(attention_fusion, optimizer, train_data, num_epochs=20)"]},{"cell_type":"markdown","metadata":{},"source":["## Storing Models"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:11:40.983214Z","iopub.status.busy":"2024-10-07T16:11:40.982817Z","iopub.status.idle":"2024-10-07T16:11:41.001619Z","shell.execute_reply":"2024-10-07T16:11:41.000839Z","shell.execute_reply.started":"2024-10-07T16:11:40.983176Z"},"trusted":true},"outputs":[],"source":["torch.save(autoencoder.state_dict(), 'autoencoder.pth')\n","torch.save(vae.state_dict(), 'vae.pth')\n","torch.save(attention_fusion.state_dict(), 'attention_fusion.pth')"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:14:43.106351Z","iopub.status.busy":"2024-10-07T16:14:43.105595Z","iopub.status.idle":"2024-10-07T16:14:43.130504Z","shell.execute_reply":"2024-10-07T16:14:43.129656Z","shell.execute_reply.started":"2024-10-07T16:14:43.106308Z"},"trusted":true},"outputs":[{"data":{"text/plain":["VAE(\n","  (fc1): Linear(in_features=512, out_features=256, bias=True)\n","  (fc21): Linear(in_features=256, out_features=128, bias=True)\n","  (fc22): Linear(in_features=256, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=256, bias=True)\n","  (fc4): Linear(in_features=256, out_features=512, bias=True)\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["autoencoder.load_state_dict(torch.load('autoencoder.pth', weights_only=True))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","autoencoder.to(device)\n","\n","vae.load_state_dict(torch.load('vae.pth', weights_only=True))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","vae.to(device)\n","\n","attention_fusion.load_state_dict(torch.load('attention_fusion.pth', weights_only=True))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","attention_fusion.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation Pipeline"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:15:08.720900Z","iopub.status.busy":"2024-10-07T16:15:08.720280Z","iopub.status.idle":"2024-10-07T16:15:08.735658Z","shell.execute_reply":"2024-10-07T16:15:08.734567Z","shell.execute_reply.started":"2024-10-07T16:15:08.720859Z"},"trusted":true},"outputs":[],"source":["def evaluate_with_cosine_distance(autoencoder, test_data):\n","    autoencoder.eval()\n","    grouped = test_data.groupby('study_id')\n","    \n","    mse_scores = []\n","    cosine_distances = []\n","    \n","    with torch.no_grad():\n","        for study_id, group in tqdm(grouped):\n","            embeddings = [row[:512].to_numpy(dtype=float) for _, row in group.iterrows()]\n","            embeddings = np.array(embeddings)\n","\n","            if len(embeddings) > 1:\n","                input_embedding = embeddings[0] \n","                noisy_embedding = input_embedding + 0.3 * np.random.randn(*input_embedding.shape)\n","                \n","                input_embedding = torch.tensor(input_embedding, dtype=torch.float32).to(device)\n","                noisy_embedding = torch.tensor(noisy_embedding, dtype=torch.float32).to(device)\n","\n","                generated_embedding = autoencoder(noisy_embedding)\n","\n","                mse = F.mse_loss(input_embedding, generated_embedding).item()\n","                mse_scores.append(mse)\n","\n","                cosine_similarity = F.cosine_similarity(input_embedding.unsqueeze(0), generated_embedding.unsqueeze(0)).item()\n","                cosine_distance = 1 - cosine_similarity\n","                cosine_distances.append(cosine_distance)\n","\n","    print(f'Average MSE on Unseen Data: {np.mean(mse_scores)}')\n","    print(f'Average Cosine Distance on Unseen Data: {np.mean(cosine_distances)}')\n","    \n","    \n","def evaluate_vae_with_cosine_distance(vae, test_data):\n","    vae.eval()\n","    grouped = test_data.groupby('study_id')\n","    \n","    mse_scores = []\n","    cosine_distances = []\n","\n","    with torch.no_grad():\n","        for study_id, group in tqdm(grouped):\n","            embeddings = [row[:512].to_numpy(dtype=float) for _, row in group.iterrows()]\n","            embeddings = np.array(embeddings)\n","\n","            if len(embeddings) > 1:\n","                input_embedding = embeddings[0]\n","                noisy_embedding = input_embedding + 0.3 * np.random.randn(*input_embedding.shape)  # Add noise\n","\n","                input_embedding = torch.tensor(input_embedding, dtype=torch.float32).to(device)\n","                noisy_embedding = torch.tensor(noisy_embedding, dtype=torch.float32).to(device)\n","\n","                reconstructed_embedding, _, _ = vae(noisy_embedding)\n","\n","                mse = F.mse_loss(input_embedding, reconstructed_embedding).item()\n","                mse_scores.append(mse)\n","\n","                cosine_similarity = F.cosine_similarity(input_embedding.unsqueeze(0), reconstructed_embedding.unsqueeze(0)).item()\n","                cosine_distance = 1 - cosine_similarity\n","                cosine_distances.append(cosine_distance)\n","\n","    print(f'Average MSE on Unseen Data: {np.mean(mse_scores)}')\n","    print(f'Average Cosine Distance on Unseen Data: {np.mean(cosine_distances)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Unseen Data Metrics"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T16:16:03.912664Z","iopub.status.busy":"2024-10-07T16:16:03.912279Z","iopub.status.idle":"2024-10-07T16:16:04.248364Z","shell.execute_reply":"2024-10-07T16:16:04.247359Z","shell.execute_reply.started":"2024-10-07T16:16:03.912628Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 376/376 [00:00<00:00, 3875.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average MSE on Unseen Data: 24.237207994378846\n","Average Cosine Distance on Unseen Data: 0.6346563293502249\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 376/376 [00:00<00:00, 3578.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average MSE on Unseen Data: 24.343631791657415\n","Average Cosine Distance on Unseen Data: 0.6387393695848256\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 376/376 [00:00<00:00, 3699.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Average MSE on Unseen Data: 27.50167006254196\n","Average Cosine Distance on Unseen Data: 0.9744737282363248\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["evaluate_with_cosine_distance(autoencoder, simulated_test_data)    \n","evaluate_vae_with_cosine_distance(vae, simulated_test_data)\n","evaluate_vae_with_cosine_distance(attention_fusion, simulated_test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5788739,"sourceId":9528888,"sourceType":"datasetVersion"},{"datasetId":5810383,"sourceId":9538829,"sourceType":"datasetVersion"},{"datasetId":5814948,"sourceId":9544899,"sourceType":"datasetVersion"},{"datasetId":5821406,"sourceId":9553895,"sourceType":"datasetVersion"}],"dockerImageVersionId":30775,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
