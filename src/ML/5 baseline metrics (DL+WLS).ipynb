{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c63b6c5",
   "metadata": {
    "papermill": {
     "duration": 0.004337,
     "end_time": "2024-10-06T11:58:06.936875",
     "exception": false,
     "start_time": "2024-10-06T11:58:06.932538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **A Novel Approach for Three-Way Classification of Lumbar Spine Degeneration Using Pseudo-Modality Learning to Handle Missing MRI Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b00ab12",
   "metadata": {},
   "source": [
    "## **Modeling Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9034f",
   "metadata": {},
   "source": [
    "![3-way Cascaded Classifier Architecture](https://github.com/ahmedembeddedxx/lumbar-spine-degenerative-classification/blob/main/architecture/classifiers-architecture/3-way-cascaded-classifier.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fdc0fd",
   "metadata": {},
   "source": [
    "## **Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001f4936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T11:58:06.953048Z",
     "iopub.status.busy": "2024-10-06T11:58:06.952679Z",
     "iopub.status.idle": "2024-10-06T11:58:21.317062Z",
     "shell.execute_reply": "2024-10-06T11:58:21.316075Z"
    },
    "papermill": {
     "duration": 14.371611,
     "end_time": "2024-10-06T11:58:21.319481",
     "exception": false,
     "start_time": "2024-10-06T11:58:06.947870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e089",
   "metadata": {},
   "source": [
    "## **Training Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f7b1c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T11:58:21.336173Z",
     "iopub.status.busy": "2024-10-06T11:58:21.335620Z",
     "iopub.status.idle": "2024-10-06T11:58:21.362575Z",
     "shell.execute_reply": "2024-10-06T11:58:21.361732Z"
    },
    "papermill": {
     "duration": 0.034041,
     "end_time": "2024-10-06T11:58:21.364459",
     "exception": false,
     "start_time": "2024-10-06T11:58:21.330418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "def compute_class_weights(y_train):\n",
    "    class_weights = {}\n",
    "    for i in range(y_train.shape[1]):\n",
    "        classes = np.unique(y_train[:, i])\n",
    "        weights = compute_class_weight('balanced', classes=classes, y=y_train[:, i])\n",
    "        class_weights[i] = {classes[0]: weights[0], classes[1]: weights[1]}\n",
    "    return class_weights\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred, weights):\n",
    "    epsilon = tf.keras.backend.epsilon()\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "    bce_loss = -(weights[1] * y_true * tf.math.log(y_pred) + weights[0] * (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "    return tf.reduce_mean(bce_loss, axis=-1)\n",
    "\n",
    "def train(embedding_path, labels_path, n_splits=5):\n",
    "    embeddings = pd.read_csv(embedding_path)\n",
    "    labels = pd.read_csv(labels_path)\n",
    "\n",
    "    id_cols = labels[['study_id', 'series_id']]\n",
    "    cols_to_impute = labels.drop(columns=['study_id', 'series_id'])\n",
    "    imputed_cols = cols_to_impute.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "    final_df = pd.concat([id_cols, imputed_cols], axis=1)\n",
    "    labels = final_df\n",
    "\n",
    "    id_cols = labels[['study_id', 'series_id']]\n",
    "    cols_to_encode = labels.drop(columns=['study_id', 'series_id'])\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_cols = encoder.fit_transform(cols_to_encode)\n",
    "    encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(cols_to_encode.columns))\n",
    "    final_df = pd.concat([id_cols, encoded_df], axis=1)\n",
    "    df = pd.merge(embeddings, final_df, on='study_id', how='inner')\n",
    "\n",
    "    fc_layer = len(df.columns[515:])\n",
    "    X = df.iloc[:, :512].values\n",
    "    Y = df.iloc[:, 515:].values\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    fold_val_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_roc_auc_scores = []\n",
    "    \n",
    "    best_test_accuracy = 0.0\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        class_weights = compute_class_weights(Y_train)\n",
    "\n",
    "        model = Sequential([\n",
    "            Input(shape=(512,)),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(fc_layer, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            loss = 0\n",
    "            for i in range(Y_train.shape[1]):\n",
    "                weights = class_weights[i]\n",
    "                loss += weighted_binary_crossentropy(y_true[:, i], y_pred[:, i], weights)\n",
    "            return loss / Y_train.shape[1]\n",
    "\n",
    "        model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
    "        history = model.fit(X_train, Y_train, epochs=20, batch_size=16, verbose=0, validation_data=(X_test, Y_test))\n",
    "\n",
    "        loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        \n",
    "        val_accuracy = np.mean(history.history['val_accuracy'])\n",
    "        fold_val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Predict on test set\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate F1 Score and ROC AUC\n",
    "        f1 = f1_score(Y_test, (Y_pred > 0.5).astype(int), average='macro', zero_division=1)\n",
    "        \n",
    "        if Y_test.sum(axis=0).min() == 0:\n",
    "            print(f\"Warning: Skipping ROC AUC for fold {fold} due to missing classes.\")\n",
    "            roc_auc = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(Y_test, Y_pred, average='macro', multi_class='ovr')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error calculating ROC AUC for fold {fold}: {e}.\")\n",
    "                roc_auc = np.nan\n",
    "        \n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_roc_auc_scores.append(roc_auc)\n",
    "\n",
    "        if accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = accuracy\n",
    "            best_val_accuracy = val_accuracy\n",
    "\n",
    "        print(f'Fold {fold}: Test Accuracy = {accuracy:.4f}, Validation Accuracy = {val_accuracy:.4f}, '\n",
    "              f'F1 Score = {f1:.4f}, ROC AUC = {roc_auc:.4f}')\n",
    "\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "    avg_f1_score = np.mean(fold_f1_scores)\n",
    "    avg_roc_auc = np.mean(fold_roc_auc_scores)\n",
    "\n",
    "    print(f'Average Test Accuracy across {n_splits} folds: {avg_accuracy:.4f}, '\n",
    "          f'Average Validation Accuracy across {n_splits} folds: {avg_val_accuracy:.4f}, '\n",
    "          f'Average F1 Score across {n_splits} folds: {avg_f1_score:.4f}, '\n",
    "          f'Average ROC AUC across {n_splits} folds: {avg_roc_auc:.4f}')\n",
    "\n",
    "    return avg_accuracy, avg_val_accuracy, best_test_accuracy, best_val_accuracy, avg_f1_score, avg_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a803c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T11:58:21.373864Z",
     "iopub.status.busy": "2024-10-06T11:58:21.373538Z",
     "iopub.status.idle": "2024-10-06T11:58:21.387540Z",
     "shell.execute_reply": "2024-10-06T11:58:21.386521Z"
    },
    "papermill": {
     "duration": 0.021456,
     "end_time": "2024-10-06T11:58:21.390176",
     "exception": false,
     "start_time": "2024-10-06T11:58:21.368720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_embeddings_paths = [\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/AT2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/AT2_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST1_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST1_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST2_attention_embeddings_hist.csv'    \n",
    "]\n",
    "\n",
    "average_embeddings_paths = [\n",
    "    '/kaggle/input/embeddings-for-rsna/at2-greyscl/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/at2-hist/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st1-greyscl/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st1-hist/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st2-greyscl/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st2-hist/final_embeddings.csv'\n",
    "]\n",
    "\n",
    "medicalnet_embeddings_paths = [\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/AT2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/AT2_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST1_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST1_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST2_attention_embeddings_hist.csv',\n",
    "]\n",
    "\n",
    "labels_paths = [\n",
    "    '/kaggle/input/preprocessed-dataset/train_data_AT2.csv',\n",
    "    '/kaggle/input/preprocessed-dataset/train_data_ST1.csv',\n",
    "    '/kaggle/input/preprocessed-dataset/train_data_ST2.csv'\n",
    "]\n",
    "\n",
    "list_of_combination = [\n",
    "    'AT2 - GSL - Attention Network',\n",
    "    'AT2 - HIST - Attention Network',\n",
    "    'ST1 - GSL - Attention Network',\n",
    "    'ST1 - HIST - Attention Network',\n",
    "    'ST2 - GSL - Attention Network',\n",
    "    'ST2 - HIST - Attention Network',\n",
    "    \n",
    "    'AT2 - GSL - Average ResNet50',\n",
    "    'AT2 - HIST - Average ResNet50',\n",
    "    'ST1 - GSL - Average ResNet50',\n",
    "    'ST1 - HIST - Average ResNet50',\n",
    "    'ST2 - GSL - Average ResNet50',\n",
    "    'ST2 - HIST - Average ResNet50',\n",
    "    \n",
    "    'AT2 - GSL - MedicalNet Network',\n",
    "    'AT2 - HIST - MedicalNet Network',\n",
    "    'ST1 - GSL - MedicalNet Network',\n",
    "    'ST1 - HIST - MedicalNet Network',\n",
    "    'ST2 - GSL - MedicalNet Network',\n",
    "    'ST2 - HIST - MedicalNet Network'\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Combination', 'Avg_Test_Accuracy', 'Avg_Val_Accuracy'])\n",
    "\n",
    "all_embedding_paths = [\n",
    "    *attention_embeddings_paths,\n",
    "    *average_embeddings_paths,\n",
    "    *medicalnet_embeddings_paths\n",
    "]\n",
    "\n",
    "corresponding_labels_paths = [\n",
    "    labels_paths[0],  # AT2 - GSL - Attention Network\n",
    "    labels_paths[0],  # AT2 - HIST - Attention Network\n",
    "    labels_paths[1],  # ST1 - GSL - Attention Network\n",
    "    labels_paths[1],  # ST1 - HIST - Attention Network\n",
    "    labels_paths[2],  # ST2 - GSL - Attention Network\n",
    "    labels_paths[2],  # ST2 - HIST - Attention Network\n",
    "    \n",
    "    labels_paths[0],  # AT2 - GSL - Average ResNet50\n",
    "    labels_paths[0],  # AT2 - HIST - Average ResNet50\n",
    "    labels_paths[1],  # ST1 - GSL - Average ResNet50\n",
    "    labels_paths[1],  # ST1 - HIST - Average ResNet50\n",
    "    labels_paths[2],  # ST2 - GSL - Average ResNet50\n",
    "    labels_paths[2],  # ST2 - HIST - Average ResNet50\n",
    "    \n",
    "    labels_paths[0],  # AT2 - GSL - MedicalNet Network\n",
    "    labels_paths[0],  # AT2 - HIST - MedicalNet Network\n",
    "    labels_paths[1],  # ST1 - GSL - MedicalNet Network\n",
    "    labels_paths[1],  # ST1 - HIST - MedicalNet Network\n",
    "    labels_paths[2],  # ST2 - GSL - MedicalNet Network\n",
    "    labels_paths[2],  # ST2 - HIST - MedicalNet Network\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94af27",
   "metadata": {},
   "source": [
    "## **Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Combination', 'Avg_Test_Accuracy', 'Avg_Val_Accuracy', 'Best_Test_Accuracy', 'Best_Val_Accuracy', 'Avg_F1_Score', 'Avg_ROC_AUC'])\n",
    "\n",
    "for embedding_path, label_path, name in zip(all_embedding_paths, corresponding_labels_paths, list_of_combination):\n",
    "    print(f\"\\nTraining for: {name} - {embedding_path}\")\n",
    "    avg_accuracy, avg_val_accuracy, best_test_accuracy, best_val_accuracy, avg_f1_score, avg_roc_auc = train(embedding_path, label_path)\n",
    "    \n",
    "    result_row = pd.DataFrame({\n",
    "        'Combination': [name],\n",
    "        'Avg_Test_Accuracy': [avg_accuracy],\n",
    "        'Avg_Val_Accuracy': [avg_val_accuracy],\n",
    "        'Best_Test_Accuracy': [best_test_accuracy],\n",
    "        'Best_Val_Accuracy': [best_val_accuracy],\n",
    "        'Avg_F1_Score' : [avg_f1_score], \n",
    "        'Avg_ROC_AUC': [avg_roc_auc],\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, result_row], ignore_index=True)\n",
    "\n",
    "print(\"\\nFinal Results DataFrame:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56723e47",
   "metadata": {},
   "source": [
    "## **Modelling Arhcitecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a88b49",
   "metadata": {},
   "source": [
    "![25-3 Way Class Architecture](https://github.com/ahmedembeddedxx/lumbar-spine-degenerative-classification/blob/main/architecture/classifiers-architecture/25-3-way-class.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481f38cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T12:26:40.686910Z",
     "iopub.status.busy": "2024-10-06T12:26:40.686522Z",
     "iopub.status.idle": "2024-10-06T12:26:40.707952Z",
     "shell.execute_reply": "2024-10-06T12:26:40.707051Z"
    },
    "papermill": {
     "duration": 0.055854,
     "end_time": "2024-10-06T12:26:40.709954",
     "exception": false,
     "start_time": "2024-10-06T12:26:40.654100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Avg_Test_Accuracy</th>\n",
       "      <th>Avg_Val_Accuracy</th>\n",
       "      <th>Best_Test_Accuracy</th>\n",
       "      <th>Best_Val_Accuracy</th>\n",
       "      <th>Avg_F1_Score</th>\n",
       "      <th>Avg_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT2 - GSL - Attention Network</td>\n",
       "      <td>0.650095</td>\n",
       "      <td>0.435885</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.436265</td>\n",
       "      <td>0.666177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT2 - HIST - Attention Network</td>\n",
       "      <td>0.685671</td>\n",
       "      <td>0.446115</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.497152</td>\n",
       "      <td>0.659777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST1 - GSL - Attention Network</td>\n",
       "      <td>0.531989</td>\n",
       "      <td>0.444556</td>\n",
       "      <td>0.605820</td>\n",
       "      <td>0.558995</td>\n",
       "      <td>0.367588</td>\n",
       "      <td>0.616761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST1 - HIST - Attention Network</td>\n",
       "      <td>0.570024</td>\n",
       "      <td>0.414752</td>\n",
       "      <td>0.625330</td>\n",
       "      <td>0.500132</td>\n",
       "      <td>0.375586</td>\n",
       "      <td>0.624202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2 - GSL - Attention Network</td>\n",
       "      <td>0.502677</td>\n",
       "      <td>0.461007</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.543067</td>\n",
       "      <td>0.364420</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ST2 - HIST - Attention Network</td>\n",
       "      <td>0.574026</td>\n",
       "      <td>0.529892</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.653324</td>\n",
       "      <td>0.358307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AT2 - GSL - Average ResNet50</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>0.233679</td>\n",
       "      <td>0.375839</td>\n",
       "      <td>0.280705</td>\n",
       "      <td>0.335861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT2 - HIST - Average ResNet50</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.238830</td>\n",
       "      <td>0.407718</td>\n",
       "      <td>0.256711</td>\n",
       "      <td>0.398538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST1 - GSL - Average ResNet50</td>\n",
       "      <td>0.250424</td>\n",
       "      <td>0.201239</td>\n",
       "      <td>0.295515</td>\n",
       "      <td>0.299077</td>\n",
       "      <td>0.351894</td>\n",
       "      <td>0.575764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ST1 - HIST - Average ResNet50</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>0.245919</td>\n",
       "      <td>0.411610</td>\n",
       "      <td>0.199077</td>\n",
       "      <td>0.380135</td>\n",
       "      <td>0.595097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ST2 - GSL - Average ResNet50</td>\n",
       "      <td>0.245139</td>\n",
       "      <td>0.198890</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.202133</td>\n",
       "      <td>0.330423</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ST2 - HIST - Average ResNet50</td>\n",
       "      <td>0.443485</td>\n",
       "      <td>0.320985</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.356844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AT2 - GSL - MedicalNet Network</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>0.041984</td>\n",
       "      <td>0.128978</td>\n",
       "      <td>0.043384</td>\n",
       "      <td>0.314732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT2 - HIST - MedicalNet Network</td>\n",
       "      <td>0.335855</td>\n",
       "      <td>0.205609</td>\n",
       "      <td>0.579565</td>\n",
       "      <td>0.093886</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ST1 - GSL - MedicalNet Network</td>\n",
       "      <td>0.298977</td>\n",
       "      <td>0.277692</td>\n",
       "      <td>0.430079</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.345138</td>\n",
       "      <td>0.568058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ST1 - HIST - MedicalNet Network</td>\n",
       "      <td>0.272523</td>\n",
       "      <td>0.343251</td>\n",
       "      <td>0.435356</td>\n",
       "      <td>0.342216</td>\n",
       "      <td>0.324897</td>\n",
       "      <td>0.546342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ST2 - GSL - MedicalNet Network</td>\n",
       "      <td>0.241504</td>\n",
       "      <td>0.171712</td>\n",
       "      <td>0.381333</td>\n",
       "      <td>0.187467</td>\n",
       "      <td>0.310898</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ST2 - HIST - MedicalNet Network</td>\n",
       "      <td>0.192969</td>\n",
       "      <td>0.137481</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.315277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Combination  Avg_Test_Accuracy  Avg_Val_Accuracy  \\\n",
       "0     AT2 - GSL - Attention Network           0.650095          0.435885   \n",
       "1    AT2 - HIST - Attention Network           0.685671          0.446115   \n",
       "2     ST1 - GSL - Attention Network           0.531989          0.444556   \n",
       "3    ST1 - HIST - Attention Network           0.570024          0.414752   \n",
       "4     ST2 - GSL - Attention Network           0.502677          0.461007   \n",
       "5    ST2 - HIST - Attention Network           0.574026          0.529892   \n",
       "6      AT2 - GSL - Average ResNet50           0.277513          0.233679   \n",
       "7     AT2 - HIST - Average ResNet50           0.356250          0.238830   \n",
       "8      ST1 - GSL - Average ResNet50           0.250424          0.201239   \n",
       "9     ST1 - HIST - Average ResNet50           0.333335          0.245919   \n",
       "10     ST2 - GSL - Average ResNet50           0.245139          0.198890   \n",
       "11    ST2 - HIST - Average ResNet50           0.443485          0.320985   \n",
       "12   AT2 - GSL - MedicalNet Network           0.032164          0.041984   \n",
       "13  AT2 - HIST - MedicalNet Network           0.335855          0.205609   \n",
       "14   ST1 - GSL - MedicalNet Network           0.298977          0.277692   \n",
       "15  ST1 - HIST - MedicalNet Network           0.272523          0.343251   \n",
       "16   ST2 - GSL - MedicalNet Network           0.241504          0.171712   \n",
       "17  ST2 - HIST - MedicalNet Network           0.192969          0.137481   \n",
       "\n",
       "    Best_Test_Accuracy  Best_Val_Accuracy  Avg_F1_Score  Avg_ROC_AUC  \n",
       "0             0.733668           0.436265      0.666177          NaN  \n",
       "1             0.783920           0.497152      0.659777          NaN  \n",
       "2             0.605820           0.558995      0.367588     0.616761  \n",
       "3             0.625330           0.500132      0.375586     0.624202  \n",
       "4             0.570667           0.543067      0.364420          NaN  \n",
       "5             0.702128           0.653324      0.358307          NaN  \n",
       "6             0.375839           0.280705      0.335861          NaN  \n",
       "7             0.407718           0.256711      0.398538          NaN  \n",
       "8             0.295515           0.299077      0.351894     0.575764  \n",
       "9             0.411610           0.199077      0.380135     0.595097  \n",
       "10            0.416000           0.202133      0.330423          NaN  \n",
       "11            0.506667           0.331600      0.356844          NaN  \n",
       "12            0.128978           0.043384      0.314732          NaN  \n",
       "13            0.579565           0.093886      0.309495          NaN  \n",
       "14            0.430079           0.182322      0.345138     0.568058  \n",
       "15            0.435356           0.342216      0.324897     0.546342  \n",
       "16            0.381333           0.187467      0.310898          NaN  \n",
       "17            0.312000           0.147600      0.315277          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76a861",
   "metadata": {
    "papermill": {
     "duration": 0.031174,
     "end_time": "2024-10-06T12:26:40.774214",
     "exception": false,
     "start_time": "2024-10-06T12:26:40.743040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Random Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3a92dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T12:26:40.838758Z",
     "iopub.status.busy": "2024-10-06T12:26:40.838406Z",
     "iopub.status.idle": "2024-10-06T12:26:40.848642Z",
     "shell.execute_reply": "2024-10-06T12:26:40.847752Z"
    },
    "papermill": {
     "duration": 0.044685,
     "end_time": "2024-10-06T12:26:40.850491",
     "exception": false,
     "start_time": "2024-10-06T12:26:40.805806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_predictions(path):\n",
    "    labels = pd.read_csv(path)\n",
    "\n",
    "    id_cols = labels[['study_id', 'series_id']]\n",
    "    cols_to_impute = labels.drop(columns=['study_id', 'series_id'])\n",
    "    imputed_cols = cols_to_impute.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "    final_df = pd.concat([id_cols, imputed_cols], axis=1)\n",
    "\n",
    "    id_cols = final_df[['study_id', 'series_id']]\n",
    "    cols_to_encode = final_df.drop(columns=['study_id', 'series_id'])\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_cols = encoder.fit_transform(cols_to_encode)\n",
    "    encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(cols_to_encode.columns))\n",
    "    final_df = pd.concat([id_cols, encoded_df], axis=1)\n",
    "\n",
    "    Y_true = final_df.drop(columns=['study_id', 'series_id']).values\n",
    "\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random_predictions = np.random.rand(*Y_true.shape)  # Random floats in [0.0, 1.0]\n",
    "\n",
    "    threshold = np.mean(random_predictions)\n",
    "\n",
    "    binary_predictions = (random_predictions > threshold).astype(float)\n",
    "\n",
    "    accuracy = np.mean(np.all(binary_predictions == Y_true, axis=1))\n",
    "\n",
    "    print(f\"Random Predictions Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Self-adjusting Threshold: {threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c7cd2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T12:26:40.914943Z",
     "iopub.status.busy": "2024-10-06T12:26:40.914104Z",
     "iopub.status.idle": "2024-10-06T12:26:41.001583Z",
     "shell.execute_reply": "2024-10-06T12:26:41.000573Z"
    },
    "papermill": {
     "duration": 0.121782,
     "end_time": "2024-10-06T12:26:41.003741",
     "exception": false,
     "start_time": "2024-10-06T12:26:40.881959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Predictions Accuracy: 0.0000\n",
      "Self-adjusting Threshold: 0.4996\n",
      "Random Predictions Accuracy: 0.0000\n",
      "Self-adjusting Threshold: 0.4995\n",
      "Random Predictions Accuracy: 0.0000\n",
      "Self-adjusting Threshold: 0.5004\n"
     ]
    }
   ],
   "source": [
    "random_predictions('/kaggle/input/preprocessed-dataset/train_data_AT2.csv')\n",
    "random_predictions('/kaggle/input/preprocessed-dataset/train_data_ST1.csv')\n",
    "random_predictions('/kaggle/input/preprocessed-dataset/train_data_ST2.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5788739,
     "sourceId": 9528888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5810383,
     "sourceId": 9538829,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5814948,
     "sourceId": 9544899,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5821406,
     "sourceId": 9553895,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1720.356944,
   "end_time": "2024-10-06T12:26:44.557580",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-06T11:58:04.200636",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
