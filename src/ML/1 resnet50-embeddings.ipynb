{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d39bb4",
   "metadata": {},
   "source": [
    "# A Novel Approach for Three-Way Classification of Lumbar Spine Degeneration Using Pseudo-Modality Learning to Handle Missing MRI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db9502",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efc990",
   "metadata": {},
   "source": [
    "## Embeddings Generator using Residual Net50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930c449",
   "metadata": {},
   "source": [
    "### AT2 Grey Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99114a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 168MB/s]\n",
      "2226it [1:50:34,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation completed and saved to 'final_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 512)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/preprocessed-dataset/train_data_AT2.csv')\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    patient_id = str(row['study_id'])\n",
    "    series_id = str(row['series_id'])\n",
    "    \n",
    "    series_path = os.path.join(\"/kaggle/input/preprocessed-dataset/grey_scale_train\", patient_id, series_id)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for slice_file in os.listdir(series_path):\n",
    "        if slice_file.endswith('.npy'):\n",
    "            slice_path = os.path.join(series_path, slice_file)\n",
    "            slice_data = np.load(slice_path)\n",
    "\n",
    "            if slice_data.ndim == 2:\n",
    "                slice_data = np.stack([slice_data] * 3, axis=0)\n",
    "            elif slice_data.ndim == 3:\n",
    "                if slice_data.shape[0] == 1:\n",
    "                    slice_data = np.repeat(slice_data, 3, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected slice shape: {slice_data.shape}\")\n",
    "\n",
    "            input_tensor = torch.from_numpy(slice_data).float()\n",
    "\n",
    "            input_tensor = transforms.Resize((224, 224))(input_tensor)\n",
    "\n",
    "            input_tensor = (input_tensor - torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)) / torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embedding = model(input_tensor)\n",
    "                embeddings.append(embedding.numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
    "        embedding_dict = {f'{i}': average_embedding[i] for i in range(512)}\n",
    "\n",
    "        embedding_dict.update({'study_id': patient_id, 'series_id': series_id})\n",
    "\n",
    "        results.append(embedding_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv('final_embeddings.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_embeddings.pth')\n",
    "\n",
    "print(\"Embeddings generation completed and saved to 'final_embeddings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1b4ac",
   "metadata": {},
   "source": [
    "### AT2 Histogram Equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd702b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 187MB/s]\n",
      "2226it [1:53:06,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation completed and saved to 'final_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 512)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/preprocessed-dataset/train_data_AT2.csv')\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    patient_id = str(row['study_id'])\n",
    "    series_id = str(row['series_id'])\n",
    "    \n",
    "    series_path = os.path.join(\"/kaggle/input/preprocessed-dataset/hist_norm_train\", patient_id, series_id)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for slice_file in os.listdir(series_path):\n",
    "        if slice_file.endswith('.npy'):\n",
    "            slice_path = os.path.join(series_path, slice_file)\n",
    "            slice_data = np.load(slice_path)\n",
    "\n",
    "            if slice_data.ndim == 2:\n",
    "                slice_data = np.stack([slice_data] * 3, axis=0)\n",
    "            elif slice_data.ndim == 3:\n",
    "                if slice_data.shape[0] == 1:\n",
    "                    slice_data = np.repeat(slice_data, 3, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected slice shape: {slice_data.shape}\")\n",
    "\n",
    "            input_tensor = torch.from_numpy(slice_data).float()\n",
    "\n",
    "            input_tensor = transforms.Resize((224, 224))(input_tensor)\n",
    "\n",
    "            input_tensor = (input_tensor - torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)) / torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embedding = model(input_tensor)\n",
    "                embeddings.append(embedding.numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
    "        embedding_dict = {f'{i}': average_embedding[i] for i in range(512)}\n",
    "\n",
    "        embedding_dict.update({'study_id': patient_id, 'series_id': series_id})\n",
    "\n",
    "        results.append(embedding_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv('final_embeddings.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_embeddings.pth')\n",
    "\n",
    "print(\"Embeddings generation completed and saved to 'final_embeddings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a17e2",
   "metadata": {},
   "source": [
    "### ST2 Grey Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:08<00:00, 12.5MB/s]\n",
      "1876it [46:50,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation completed and saved to 'final_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 512)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/preprocessed-dataset/train_data_ST2.csv')\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    patient_id = str(row['study_id'])\n",
    "    series_id = str(row['series_id'])\n",
    "    \n",
    "    series_path = os.path.join(\"/kaggle/input/preprocessed-dataset/grey_scale_train\", patient_id, series_id)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for slice_file in os.listdir(series_path):\n",
    "        if slice_file.endswith('.npy'):\n",
    "            slice_path = os.path.join(series_path, slice_file)\n",
    "            slice_data = np.load(slice_path)\n",
    "\n",
    "            if slice_data.ndim == 2:\n",
    "                slice_data = np.stack([slice_data] * 3, axis=0)\n",
    "            elif slice_data.ndim == 3:\n",
    "                if slice_data.shape[0] == 1:\n",
    "                    slice_data = np.repeat(slice_data, 3, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected slice shape: {slice_data.shape}\")\n",
    "\n",
    "            input_tensor = torch.from_numpy(slice_data).float()\n",
    "\n",
    "            input_tensor = transforms.Resize((224, 224))(input_tensor)\n",
    "\n",
    "            input_tensor = (input_tensor - torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)) / torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embedding = model(input_tensor)\n",
    "                embeddings.append(embedding.numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
    "        embedding_dict = {f'{i}': average_embedding[i] for i in range(512)}\n",
    "\n",
    "        embedding_dict.update({'study_id': patient_id, 'series_id': series_id})\n",
    "\n",
    "        results.append(embedding_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv('final_embeddings.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_embeddings.pth')\n",
    "\n",
    "print(\"Embeddings generation completed and saved to 'final_embeddings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0b520",
   "metadata": {},
   "source": [
    "### ST2 Histogram Equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05363cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 182MB/s]\n",
      "1876it [44:25,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation completed and saved to 'final_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 512)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/preprocessed-dataset/train_data_ST2.csv')\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    patient_id = str(row['study_id'])\n",
    "    series_id = str(row['series_id'])\n",
    "    \n",
    "    series_path = os.path.join(\"/kaggle/input/preprocessed-dataset/hist_norm_train\", patient_id, series_id)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for slice_file in os.listdir(series_path):\n",
    "        if slice_file.endswith('.npy'):\n",
    "            slice_path = os.path.join(series_path, slice_file)\n",
    "            slice_data = np.load(slice_path)\n",
    "\n",
    "            if slice_data.ndim == 2:\n",
    "                slice_data = np.stack([slice_data] * 3, axis=0)\n",
    "            elif slice_data.ndim == 3:\n",
    "                if slice_data.shape[0] == 1:\n",
    "                    slice_data = np.repeat(slice_data, 3, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected slice shape: {slice_data.shape}\")\n",
    "\n",
    "            input_tensor = torch.from_numpy(slice_data).float()\n",
    "\n",
    "            input_tensor = transforms.Resize((224, 224))(input_tensor)\n",
    "\n",
    "            input_tensor = (input_tensor - torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)) / torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embedding = model(input_tensor)\n",
    "                embeddings.append(embedding.numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
    "        embedding_dict = {f'{i}': average_embedding[i] for i in range(512)}\n",
    "\n",
    "        embedding_dict.update({'study_id': patient_id, 'series_id': series_id})\n",
    "\n",
    "        results.append(embedding_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv('final_embeddings.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_embeddings.pth')\n",
    "\n",
    "print(\"Embeddings generation completed and saved to 'final_embeddings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2d453",
   "metadata": {},
   "source": [
    "### ST1 Grey Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92e764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 196MB/s]\n",
      "1881it [47:25,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation completed and saved to 'final_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 512)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/preprocessed-dataset/train_data_ST1.csv')\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    patient_id = str(row['study_id'])\n",
    "    series_id = str(row['series_id'])\n",
    "    \n",
    "    series_path = os.path.join(\"/kaggle/input/preprocessed-dataset/grey_scale_train\", patient_id, series_id)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for slice_file in os.listdir(series_path):\n",
    "        if slice_file.endswith('.npy'):\n",
    "            slice_path = os.path.join(series_path, slice_file)\n",
    "            slice_data = np.load(slice_path)\n",
    "\n",
    "            if slice_data.ndim == 2:\n",
    "                slice_data = np.stack([slice_data] * 3, axis=0)\n",
    "            elif slice_data.ndim == 3:\n",
    "                if slice_data.shape[0] == 1:\n",
    "                    slice_data = np.repeat(slice_data, 3, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected slice shape: {slice_data.shape}\")\n",
    "\n",
    "            input_tensor = torch.from_numpy(slice_data).float()\n",
    "\n",
    "            input_tensor = transforms.Resize((224, 224))(input_tensor)\n",
    "\n",
    "            input_tensor = (input_tensor - torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)) / torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embedding = model(input_tensor)\n",
    "                embeddings.append(embedding.numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
    "        embedding_dict = {f'{i}': average_embedding[i] for i in range(512)}\n",
    "\n",
    "        embedding_dict.update({'study_id': patient_id, 'series_id': series_id})\n",
    "\n",
    "        results.append(embedding_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv('final_embeddings.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_embeddings.pth')\n",
    "\n",
    "print(\"Embeddings generation completed and saved to 'final_embeddings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b470ff",
   "metadata": {},
   "source": [
    "### ST1 Historgram Equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b79f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n",
      "1881it [50:34,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation completed and saved to 'final_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 512)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/preprocessed-dataset/train_data_ST1.csv')\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    patient_id = str(row['study_id'])\n",
    "    series_id = str(row['series_id'])\n",
    "    \n",
    "    series_path = os.path.join(\"/kaggle/input/preprocessed-dataset/hist_norm_train\", patient_id, series_id)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for slice_file in os.listdir(series_path):\n",
    "        if slice_file.endswith('.npy'):\n",
    "            slice_path = os.path.join(series_path, slice_file)\n",
    "            slice_data = np.load(slice_path)\n",
    "\n",
    "            if slice_data.ndim == 2:\n",
    "                slice_data = np.stack([slice_data] * 3, axis=0)\n",
    "            elif slice_data.ndim == 3:\n",
    "                if slice_data.shape[0] == 1:\n",
    "                    slice_data = np.repeat(slice_data, 3, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected slice shape: {slice_data.shape}\")\n",
    "\n",
    "            input_tensor = torch.from_numpy(slice_data).float()\n",
    "\n",
    "            input_tensor = transforms.Resize((224, 224))(input_tensor)\n",
    "\n",
    "            input_tensor = (input_tensor - torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)) / torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "            input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embedding = model(input_tensor)\n",
    "                embeddings.append(embedding.numpy())\n",
    "\n",
    "    if embeddings:\n",
    "        average_embedding = np.mean(np.vstack(embeddings), axis=0)\n",
    "        embedding_dict = {f'{i}': average_embedding[i] for i in range(512)}\n",
    "\n",
    "        embedding_dict.update({'study_id': patient_id, 'series_id': series_id})\n",
    "\n",
    "        results.append(embedding_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv('final_embeddings.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_embeddings.pth')\n",
    "\n",
    "print(\"Embeddings generation completed and saved to 'final_embeddings.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5788739,
     "sourceId": 9528888,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3053.814089,
   "end_time": "2024-10-03T05:57:31.300746",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-03T05:06:37.486657",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
