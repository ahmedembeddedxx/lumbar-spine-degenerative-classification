{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5da3cac",
   "metadata": {
    "papermill": {
     "duration": 0.00574,
     "end_time": "2024-10-11T13:47:15.407743",
     "exception": false,
     "start_time": "2024-10-11T13:47:15.402003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **A Novel Approach for Three-Way Classification of Lumbar Spine Degeneration Using Pseudo-Modality Learning to Handle Missing MRI Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df7098",
   "metadata": {},
   "source": [
    "<img src=\"../../architecture/classifiers-architecture/3-way-cascaded-classifier.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf0b1f",
   "metadata": {
    "papermill": {
     "duration": 0.004718,
     "end_time": "2024-10-11T13:47:15.417751",
     "exception": false,
     "start_time": "2024-10-11T13:47:15.413033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f075535b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T13:47:15.430356Z",
     "iopub.status.busy": "2024-10-11T13:47:15.429178Z",
     "iopub.status.idle": "2024-10-11T13:47:32.848134Z",
     "shell.execute_reply": "2024-10-11T13:47:32.846980Z"
    },
    "papermill": {
     "duration": 17.428952,
     "end_time": "2024-10-11T13:47:32.851781",
     "exception": false,
     "start_time": "2024-10-11T13:47:15.422829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d190195",
   "metadata": {
    "papermill": {
     "duration": 0.004391,
     "end_time": "2024-10-11T13:47:32.861223",
     "exception": false,
     "start_time": "2024-10-11T13:47:32.856832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Training Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1c4509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T13:47:32.873066Z",
     "iopub.status.busy": "2024-10-11T13:47:32.872316Z",
     "iopub.status.idle": "2024-10-11T13:47:32.891752Z",
     "shell.execute_reply": "2024-10-11T13:47:32.890621Z"
    },
    "papermill": {
     "duration": 0.028396,
     "end_time": "2024-10-11T13:47:32.894271",
     "exception": false,
     "start_time": "2024-10-11T13:47:32.865875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_embeddings_paths = [\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/AT2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/AT2_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST1_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST1_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/attention-embeddings-for-rsna/ST2_attention_embeddings_hist.csv'    \n",
    "]\n",
    "\n",
    "average_embeddings_paths = [\n",
    "    '/kaggle/input/embeddings-for-rsna/at2-greyscl/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/at2-hist/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st1-greyscl/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st1-hist/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st2-greyscl/final_embeddings.csv',\n",
    "    '/kaggle/input/embeddings-for-rsna/st2-hist/final_embeddings.csv'\n",
    "]\n",
    "\n",
    "medicalnet_embeddings_paths = [\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/AT2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/AT2_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST1_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST1_attention_embeddings_hist.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST2_attention_embeddings_gsl.csv',\n",
    "    '/kaggle/input/medicalnet-attention-layers-for-rsna/ST2_attention_embeddings_hist.csv',\n",
    "]\n",
    "\n",
    "labels_paths = [\n",
    "    '/kaggle/input/preprocessed-dataset/train_data_AT2.csv',\n",
    "    '/kaggle/input/preprocessed-dataset/train_data_ST1.csv',\n",
    "    '/kaggle/input/preprocessed-dataset/train_data_ST2.csv'\n",
    "]\n",
    "\n",
    "list_of_combination = [\n",
    "    'AT2 - GSL - Attention Network',\n",
    "    'AT2 - HIST - Attention Network',\n",
    "    'ST1 - GSL - Attention Network',\n",
    "    'ST1 - HIST - Attention Network',\n",
    "    'ST2 - GSL - Attention Network',\n",
    "    'ST2 - HIST - Attention Network',\n",
    "    \n",
    "    'AT2 - GSL - Average ResNet50',\n",
    "    'AT2 - HIST - Average ResNet50',\n",
    "    'ST1 - GSL - Average ResNet50',\n",
    "    'ST1 - HIST - Average ResNet50',\n",
    "    'ST2 - GSL - Average ResNet50',\n",
    "    'ST2 - HIST - Average ResNet50',\n",
    "    \n",
    "    'AT2 - GSL - MedicalNet Network',\n",
    "    'AT2 - HIST - MedicalNet Network',\n",
    "    'ST1 - GSL - MedicalNet Network',\n",
    "    'ST1 - HIST - MedicalNet Network',\n",
    "    'ST2 - GSL - MedicalNet Network',\n",
    "    'ST2 - HIST - MedicalNet Network'\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Combination', 'Avg_Test_Accuracy', 'Avg_Val_Accuracy'])\n",
    "\n",
    "all_embedding_paths = [\n",
    "    *attention_embeddings_paths,\n",
    "    *average_embeddings_paths,\n",
    "    *medicalnet_embeddings_paths\n",
    "]\n",
    "\n",
    "corresponding_labels_paths = [\n",
    "    labels_paths[0],  # AT2 - GSL - Attention Network\n",
    "    labels_paths[0],  # AT2 - HIST - Attention Network\n",
    "    labels_paths[1],  # ST1 - GSL - Attention Network\n",
    "    labels_paths[1],  # ST1 - HIST - Attention Network\n",
    "    labels_paths[2],  # ST2 - GSL - Attention Network\n",
    "    labels_paths[2],  # ST2 - HIST - Attention Network\n",
    "    \n",
    "    labels_paths[0],  # AT2 - GSL - Average ResNet50\n",
    "    labels_paths[0],  # AT2 - HIST - Average ResNet50\n",
    "    labels_paths[1],  # ST1 - GSL - Average ResNet50\n",
    "    labels_paths[1],  # ST1 - HIST - Average ResNet50\n",
    "    labels_paths[2],  # ST2 - GSL - Average ResNet50\n",
    "    labels_paths[2],  # ST2 - HIST - Average ResNet50\n",
    "    \n",
    "    labels_paths[0],  # AT2 - GSL - MedicalNet Network\n",
    "    labels_paths[0],  # AT2 - HIST - MedicalNet Network\n",
    "    labels_paths[1],  # ST1 - GSL - MedicalNet Network\n",
    "    labels_paths[1],  # ST1 - HIST - MedicalNet Network\n",
    "    labels_paths[2],  # ST2 - GSL - MedicalNet Network\n",
    "    labels_paths[2],  # ST2 - HIST - MedicalNet Network\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef1ef15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T13:47:32.906154Z",
     "iopub.status.busy": "2024-10-11T13:47:32.905696Z",
     "iopub.status.idle": "2024-10-11T13:47:32.928099Z",
     "shell.execute_reply": "2024-10-11T13:47:32.927038Z"
    },
    "papermill": {
     "duration": 0.03171,
     "end_time": "2024-10-11T13:47:32.930640",
     "exception": false,
     "start_time": "2024-10-11T13:47:32.898930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(embedding_path, labels_path, model_save_path_prefix='svm_model_col_'):\n",
    "    embeddings = pd.read_csv(embedding_path)\n",
    "    labels = pd.read_csv(labels_path)\n",
    "\n",
    "    id_cols = labels[['study_id', 'series_id']]\n",
    "    cols_to_impute = labels.drop(columns=['study_id', 'series_id'])\n",
    "    imputed_cols = cols_to_impute.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "    labels = pd.concat([id_cols, imputed_cols], axis=1)\n",
    "\n",
    "    id_cols = labels[['study_id', 'series_id']]\n",
    "    cols_to_encode = labels.drop(columns=['study_id', 'series_id'])\n",
    "    encoded_df = cols_to_encode.apply(LabelEncoder().fit_transform)\n",
    "    final_df = pd.concat([id_cols, encoded_df], axis=1)\n",
    "\n",
    "    df = pd.merge(embeddings, final_df, on='study_id', how='inner')\n",
    "\n",
    "    X = df.iloc[:, :512].values\n",
    "    Y = df.iloc[:, 515:].values\n",
    "\n",
    "    avg_accuracies = []\n",
    "    avg_f1_scores = []\n",
    "    avg_roc_auc_scores = []\n",
    "\n",
    "    for col in tqdm(range(Y.shape[1]), desc=\"Training Columns\"):\n",
    "        label_2_samples = df[df.iloc[:, 515 + col] == 2]\n",
    "        \n",
    "        label_1_samples = df[df.iloc[:, 515 + col] == 1]\n",
    "        \n",
    "        label_0_samples = df[df.iloc[:, 515 + col] == 0].sample(\n",
    "            max(600 - len(label_2_samples) - len(label_1_samples), 0), random_state=42\n",
    "        )\n",
    "\n",
    "        sampled_df = pd.concat([label_2_samples, label_1_samples, label_0_samples])\n",
    "        \n",
    "        X_sampled = sampled_df.iloc[:, :512].values\n",
    "        Y_sampled = sampled_df.iloc[:, 515 + col].values\n",
    "\n",
    "        unique, counts = np.unique(Y_sampled, return_counts=True)\n",
    "        if np.min(counts) < 2:\n",
    "            print(f\"Skipping column {col} due to insufficient class samples.\")\n",
    "            continue \n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X_sampled, Y_sampled, test_size=0.2, random_state=42, stratify=Y_sampled\n",
    "        )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        try:\n",
    "            minority_class_size = min(np.bincount(Y_train))\n",
    "            n_neighbors = min(5, minority_class_size - 1)  \n",
    "            smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "            X_train_smote, Y_train_smote = smote.fit_resample(X_train, Y_train)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping SMOTE for column {col} due to error: {e}\")\n",
    "            X_train_smote, Y_train_smote = X_train, Y_train\n",
    "\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(X_train_smote, Y_train_smote)\n",
    "\n",
    "        Y_pred = model.predict(X_test)\n",
    "        Y_prob = model.predict_proba(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "\n",
    "        if len(np.unique(Y_test)) < 2:\n",
    "            roc_auc = np.nan\n",
    "        else:\n",
    "            if len(np.unique(Y_test)) > 2:\n",
    "                roc_auc = roc_auc_score(Y_test, Y_prob, average='macro', multi_class='ovr')\n",
    "            else:\n",
    "                roc_auc = roc_auc_score(Y_test, Y_prob[:, 1], average='macro')\n",
    "\n",
    "        avg_accuracies.append(accuracy)\n",
    "        avg_f1_scores.append(f1)\n",
    "        avg_roc_auc_scores.append(roc_auc)\n",
    "\n",
    "        joblib.dump(model, f'{model_save_path_prefix}{col}.joblib')\n",
    "\n",
    "        print(f'Column {col}: Accuracy = {accuracy:.4f}, F1 Score = {f1:.4f}, ROC AUC = {roc_auc:.4f}')\n",
    "\n",
    "    return np.mean(avg_accuracies), np.mean(avg_f1_scores), np.mean(avg_roc_auc_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ceffb7",
   "metadata": {},
   "source": [
    "## **Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7961ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Combination', 'Avg_Test_Accuracy', 'Avg_F1_Score', 'Avg_ROC_AUC'])\n",
    "\n",
    "for embedding_path, label_path, name in zip(all_embedding_paths, corresponding_labels_paths, list_of_combination):\n",
    "    print(f\"\\nTraining for: {name} - {embedding_path}\")\n",
    "    \n",
    "    model_save_path_prefix = f'{name}_svm_model_col_'\n",
    "    \n",
    "    avg_accuracy, avg_f1_score, avg_roc_auc = train(embedding_path, label_path, model_save_path_prefix)\n",
    "    \n",
    "    result_row = pd.DataFrame({\n",
    "        'Combination': [name],\n",
    "        'Avg_Test_Accuracy': [avg_accuracy],\n",
    "        'Avg_F1_Score': [avg_f1_score], \n",
    "        'Avg_ROC_AUC': [avg_roc_auc],\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, result_row], ignore_index=True)\n",
    "\n",
    "results_df.to_csv('results_summary.csv', index=False)\n",
    "\n",
    "print(\"Training complete. Results saved to 'results_summary.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b50ebf",
   "metadata": {},
   "source": [
    "## **Modeling Arhitecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b2780",
   "metadata": {},
   "source": [
    "<img src=\"../../architecture/classifiers-architecture/25-3-way-class.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3845d287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T13:55:12.293504Z",
     "iopub.status.busy": "2024-10-11T13:55:12.292475Z",
     "iopub.status.idle": "2024-10-11T13:55:12.312461Z",
     "shell.execute_reply": "2024-10-11T13:55:12.311354Z"
    },
    "papermill": {
     "duration": 0.063015,
     "end_time": "2024-10-11T13:55:12.314939",
     "exception": false,
     "start_time": "2024-10-11T13:55:12.251924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Avg_Test_Accuracy</th>\n",
       "      <th>Avg_F1_Score</th>\n",
       "      <th>Avg_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT2 - GSL - Attention Network</td>\n",
       "      <td>0.945937</td>\n",
       "      <td>0.798812</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT2 - HIST - Attention Network</td>\n",
       "      <td>0.941098</td>\n",
       "      <td>0.784084</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST1 - GSL - Attention Network</td>\n",
       "      <td>0.800999</td>\n",
       "      <td>0.535627</td>\n",
       "      <td>0.571390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST1 - HIST - Attention Network</td>\n",
       "      <td>0.812111</td>\n",
       "      <td>0.537605</td>\n",
       "      <td>0.568919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2 - GSL - Attention Network</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.523159</td>\n",
       "      <td>0.687749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ST2 - HIST - Attention Network</td>\n",
       "      <td>0.895313</td>\n",
       "      <td>0.499455</td>\n",
       "      <td>0.583874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AT2 - GSL - Average ResNet50</td>\n",
       "      <td>0.948287</td>\n",
       "      <td>0.611106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT2 - HIST - Average ResNet50</td>\n",
       "      <td>0.948290</td>\n",
       "      <td>0.675196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST1 - GSL - Average ResNet50</td>\n",
       "      <td>0.872699</td>\n",
       "      <td>0.506946</td>\n",
       "      <td>0.569653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ST1 - HIST - Average ResNet50</td>\n",
       "      <td>0.868936</td>\n",
       "      <td>0.521133</td>\n",
       "      <td>0.544599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ST2 - GSL - Average ResNet50</td>\n",
       "      <td>0.945258</td>\n",
       "      <td>0.485579</td>\n",
       "      <td>0.655332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ST2 - HIST - Average ResNet50</td>\n",
       "      <td>0.941272</td>\n",
       "      <td>0.506565</td>\n",
       "      <td>0.624146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AT2 - GSL - MedicalNet Network</td>\n",
       "      <td>0.945788</td>\n",
       "      <td>0.587587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT2 - HIST - MedicalNet Network</td>\n",
       "      <td>0.946676</td>\n",
       "      <td>0.618213</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ST1 - GSL - MedicalNet Network</td>\n",
       "      <td>0.810613</td>\n",
       "      <td>0.505009</td>\n",
       "      <td>0.520635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ST1 - HIST - MedicalNet Network</td>\n",
       "      <td>0.820596</td>\n",
       "      <td>0.517692</td>\n",
       "      <td>0.523963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ST2 - GSL - MedicalNet Network</td>\n",
       "      <td>0.899359</td>\n",
       "      <td>0.502444</td>\n",
       "      <td>0.475248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ST2 - HIST - MedicalNet Network</td>\n",
       "      <td>0.917838</td>\n",
       "      <td>0.506720</td>\n",
       "      <td>0.414169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Combination  Avg_Test_Accuracy  Avg_F1_Score  \\\n",
       "0     AT2 - GSL - Attention Network           0.945937      0.798812   \n",
       "1    AT2 - HIST - Attention Network           0.941098      0.784084   \n",
       "2     ST1 - GSL - Attention Network           0.800999      0.535627   \n",
       "3    ST1 - HIST - Attention Network           0.812111      0.537605   \n",
       "4     ST2 - GSL - Attention Network           0.914117      0.523159   \n",
       "5    ST2 - HIST - Attention Network           0.895313      0.499455   \n",
       "6      AT2 - GSL - Average ResNet50           0.948287      0.611106   \n",
       "7     AT2 - HIST - Average ResNet50           0.948290      0.675196   \n",
       "8      ST1 - GSL - Average ResNet50           0.872699      0.506946   \n",
       "9     ST1 - HIST - Average ResNet50           0.868936      0.521133   \n",
       "10     ST2 - GSL - Average ResNet50           0.945258      0.485579   \n",
       "11    ST2 - HIST - Average ResNet50           0.941272      0.506565   \n",
       "12   AT2 - GSL - MedicalNet Network           0.945788      0.587587   \n",
       "13  AT2 - HIST - MedicalNet Network           0.946676      0.618213   \n",
       "14   ST1 - GSL - MedicalNet Network           0.810613      0.505009   \n",
       "15  ST1 - HIST - MedicalNet Network           0.820596      0.517692   \n",
       "16   ST2 - GSL - MedicalNet Network           0.899359      0.502444   \n",
       "17  ST2 - HIST - MedicalNet Network           0.917838      0.506720   \n",
       "\n",
       "    Avg_ROC_AUC  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2      0.571390  \n",
       "3      0.568919  \n",
       "4      0.687749  \n",
       "5      0.583874  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8      0.569653  \n",
       "9      0.544599  \n",
       "10     0.655332  \n",
       "11     0.624146  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14     0.520635  \n",
       "15     0.523963  \n",
       "16     0.475248  \n",
       "17     0.414169  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f7d8a",
   "metadata": {
    "papermill": {
     "duration": 0.039578,
     "end_time": "2024-10-11T13:55:12.393911",
     "exception": false,
     "start_time": "2024-10-11T13:55:12.354333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Random Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b51985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T13:55:12.474987Z",
     "iopub.status.busy": "2024-10-11T13:55:12.474569Z",
     "iopub.status.idle": "2024-10-11T13:55:12.486475Z",
     "shell.execute_reply": "2024-10-11T13:55:12.485508Z"
    },
    "papermill": {
     "duration": 0.055254,
     "end_time": "2024-10-11T13:55:12.488866",
     "exception": false,
     "start_time": "2024-10-11T13:55:12.433612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_predictions(path):\n",
    "    labels = pd.read_csv(path)\n",
    "\n",
    "    id_cols = labels[['study_id', 'series_id']]\n",
    "    cols_to_impute = labels.drop(columns=['study_id', 'series_id'])\n",
    "    imputed_cols = cols_to_impute.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "    final_df = pd.concat([id_cols, imputed_cols], axis=1)\n",
    "\n",
    "    id_cols = final_df[['study_id', 'series_id']]\n",
    "    cols_to_encode = final_df.drop(columns=['study_id', 'series_id'])\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_cols = encoder.fit_transform(cols_to_encode)\n",
    "    encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(cols_to_encode.columns))\n",
    "    final_df = pd.concat([id_cols, encoded_df], axis=1)\n",
    "\n",
    "    Y_true = final_df.drop(columns=['study_id', 'series_id']).values\n",
    "\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random_predictions = np.random.rand(*Y_true.shape)  # Random floats in [0.0, 1.0]\n",
    "\n",
    "    threshold = np.mean(random_predictions)\n",
    "\n",
    "    binary_predictions = (random_predictions > threshold).astype(float)\n",
    "\n",
    "    accuracy = np.mean(np.all(binary_predictions == Y_true, axis=1))\n",
    "\n",
    "    print(f\"Random Predictions Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Self-adjusting Threshold: {threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8d3db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T13:55:12.570220Z",
     "iopub.status.busy": "2024-10-11T13:55:12.569415Z",
     "iopub.status.idle": "2024-10-11T13:55:12.672767Z",
     "shell.execute_reply": "2024-10-11T13:55:12.671489Z"
    },
    "papermill": {
     "duration": 0.147,
     "end_time": "2024-10-11T13:55:12.675498",
     "exception": false,
     "start_time": "2024-10-11T13:55:12.528498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Predictions Accuracy: 0.0000\n",
      "Self-adjusting Threshold: 0.4996\n",
      "Random Predictions Accuracy: 0.0000\n",
      "Self-adjusting Threshold: 0.4995\n",
      "Random Predictions Accuracy: 0.0000\n",
      "Self-adjusting Threshold: 0.5004\n"
     ]
    }
   ],
   "source": [
    "random_predictions('/kaggle/input/preprocessed-dataset/train_data_AT2.csv')\n",
    "random_predictions('/kaggle/input/preprocessed-dataset/train_data_ST1.csv')\n",
    "random_predictions('/kaggle/input/preprocessed-dataset/train_data_ST2.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5788739,
     "sourceId": 9528888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5810383,
     "sourceId": 9538829,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5814948,
     "sourceId": 9544899,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5821406,
     "sourceId": 9553895,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 482.740938,
   "end_time": "2024-10-11T13:55:15.225950",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-11T13:47:12.485012",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
